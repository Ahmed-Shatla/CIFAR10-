{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyPqKdm0L7UUngpD0dx/72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-Shatla/CIFAR10-/blob/main/Achieve_high_accuracy_on_image_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "92akIXXf3mAO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train) , (x_test,y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "id": "LeAC0JpcuKiT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training data = \", x_train.shape)\n",
        "print(\"testing data = \", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RMqU254yevm",
        "outputId": "612cf792-04ff-4379-e273-d41df3e0ac00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data =  (50000, 32, 32, 3)\n",
            "testing data =  (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_train = (x_train-mean)/std\n",
        "x_test = (x_test-mean)/std\n"
      ],
      "metadata": {
        "id": "p3gwZ3UKyt1g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes)\n",
        "y_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpwbHc8t0JcN",
        "outputId": "d5380c4f-2857-4220-d36a-39c84360db02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# instantiate an empty sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "# notice that we defined the input_shape here because this is the first CONV layer.\n",
        "# we donâ€™t need to do that for the remaining layers\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q2c97a01RT6",
        "outputId": "42fac5b3-b503-4344-de4a-ad6bf19a9dee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         147712    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                40970     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 847146 (3.23 MB)\n",
            "Trainable params: 845738 (3.23 MB)\n",
            "Non-trainable params: 1408 (5.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "# compute the data augmentation on the training set\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "swQph2Sh2r-w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs=125\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.125epochs.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "# you can try any of these optimizers by uncommenting the line\n",
        "# optimizer = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "# optimizer = keras.optimizers.adam(lr=0.0005,decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n",
        "                steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,verbose=2,\n",
        "                validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF3QZWRK20PF",
        "outputId": "4b51a1fa-b413-4f0c-d754-ab69b32c36ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1d5a5adf8f3e>:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 1.55283, saving model to model.125epochs.hdf5\n",
            "781/781 - 47s - loss: 2.2880 - accuracy: 0.4148 - val_loss: 1.5528 - val_accuracy: 0.5605 - 47s/epoch - 60ms/step\n",
            "Epoch 2/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 1.55283 to 1.29820, saving model to model.125epochs.hdf5\n",
            "781/781 - 34s - loss: 1.6090 - accuracy: 0.5694 - val_loss: 1.2982 - val_accuracy: 0.6240 - 34s/epoch - 43ms/step\n",
            "Epoch 3/125\n",
            "\n",
            "Epoch 3: val_loss improved from 1.29820 to 1.22958, saving model to model.125epochs.hdf5\n",
            "781/781 - 35s - loss: 1.3577 - accuracy: 0.6355 - val_loss: 1.2296 - val_accuracy: 0.6514 - 35s/epoch - 44ms/step\n",
            "Epoch 4/125\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.22958\n",
            "781/781 - 35s - loss: 1.2285 - accuracy: 0.6630 - val_loss: 1.7497 - val_accuracy: 0.6624 - 35s/epoch - 44ms/step\n",
            "Epoch 5/125\n",
            "\n",
            "Epoch 5: val_loss improved from 1.22958 to 0.96247, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 1.1046 - accuracy: 0.6941 - val_loss: 0.9625 - val_accuracy: 0.7411 - 33s/epoch - 43ms/step\n",
            "Epoch 6/125\n",
            "\n",
            "Epoch 6: val_loss improved from 0.96247 to 0.91467, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 0.9827 - accuracy: 0.7228 - val_loss: 0.9147 - val_accuracy: 0.7589 - 33s/epoch - 42ms/step\n",
            "Epoch 7/125\n",
            "\n",
            "Epoch 7: val_loss improved from 0.91467 to 0.81873, saving model to model.125epochs.hdf5\n",
            "781/781 - 35s - loss: 0.9310 - accuracy: 0.7385 - val_loss: 0.8187 - val_accuracy: 0.7757 - 35s/epoch - 45ms/step\n",
            "Epoch 8/125\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.81873\n",
            "781/781 - 34s - loss: 0.8882 - accuracy: 0.7542 - val_loss: 0.8960 - val_accuracy: 0.7655 - 34s/epoch - 44ms/step\n",
            "Epoch 9/125\n",
            "\n",
            "Epoch 9: val_loss improved from 0.81873 to 0.73169, saving model to model.125epochs.hdf5\n",
            "781/781 - 35s - loss: 0.8565 - accuracy: 0.7632 - val_loss: 0.7317 - val_accuracy: 0.8067 - 35s/epoch - 45ms/step\n",
            "Epoch 10/125\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.73169\n",
            "781/781 - 34s - loss: 0.8322 - accuracy: 0.7743 - val_loss: 0.7942 - val_accuracy: 0.7911 - 34s/epoch - 44ms/step\n",
            "Epoch 11/125\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.73169\n",
            "781/781 - 33s - loss: 0.8087 - accuracy: 0.7802 - val_loss: 0.8200 - val_accuracy: 0.7822 - 33s/epoch - 42ms/step\n",
            "Epoch 12/125\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.73169\n",
            "781/781 - 33s - loss: 0.7946 - accuracy: 0.7865 - val_loss: 0.7656 - val_accuracy: 0.7991 - 33s/epoch - 42ms/step\n",
            "Epoch 13/125\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.73169\n",
            "781/781 - 35s - loss: 0.7794 - accuracy: 0.7931 - val_loss: 0.7327 - val_accuracy: 0.8180 - 35s/epoch - 45ms/step\n",
            "Epoch 14/125\n",
            "\n",
            "Epoch 14: val_loss improved from 0.73169 to 0.67950, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 0.7618 - accuracy: 0.7972 - val_loss: 0.6795 - val_accuracy: 0.8310 - 33s/epoch - 43ms/step\n",
            "Epoch 15/125\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.67950\n",
            "781/781 - 33s - loss: 0.7460 - accuracy: 0.8035 - val_loss: 0.7383 - val_accuracy: 0.8109 - 33s/epoch - 43ms/step\n",
            "Epoch 16/125\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.67950\n",
            "781/781 - 33s - loss: 0.7380 - accuracy: 0.8042 - val_loss: 0.7114 - val_accuracy: 0.8226 - 33s/epoch - 43ms/step\n",
            "Epoch 17/125\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.67950\n",
            "781/781 - 33s - loss: 0.7302 - accuracy: 0.8111 - val_loss: 0.7020 - val_accuracy: 0.8285 - 33s/epoch - 43ms/step\n",
            "Epoch 18/125\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.67950\n",
            "781/781 - 35s - loss: 0.7213 - accuracy: 0.8134 - val_loss: 0.6847 - val_accuracy: 0.8340 - 35s/epoch - 45ms/step\n",
            "Epoch 19/125\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.67950\n",
            "781/781 - 35s - loss: 0.7133 - accuracy: 0.8154 - val_loss: 0.7032 - val_accuracy: 0.8283 - 35s/epoch - 44ms/step\n",
            "Epoch 20/125\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.67950\n",
            "781/781 - 33s - loss: 0.7066 - accuracy: 0.8195 - val_loss: 0.7342 - val_accuracy: 0.8138 - 33s/epoch - 42ms/step\n",
            "Epoch 21/125\n",
            "\n",
            "Epoch 21: val_loss improved from 0.67950 to 0.66732, saving model to model.125epochs.hdf5\n",
            "781/781 - 34s - loss: 0.7051 - accuracy: 0.8214 - val_loss: 0.6673 - val_accuracy: 0.8395 - 34s/epoch - 43ms/step\n",
            "Epoch 22/125\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.66732\n",
            "781/781 - 34s - loss: 0.7011 - accuracy: 0.8239 - val_loss: 0.7370 - val_accuracy: 0.8173 - 34s/epoch - 44ms/step\n",
            "Epoch 23/125\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.66732\n",
            "781/781 - 35s - loss: 0.6958 - accuracy: 0.8239 - val_loss: 0.6795 - val_accuracy: 0.8332 - 35s/epoch - 44ms/step\n",
            "Epoch 24/125\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.66732\n",
            "781/781 - 34s - loss: 0.6888 - accuracy: 0.8264 - val_loss: 0.7116 - val_accuracy: 0.8324 - 34s/epoch - 43ms/step\n",
            "Epoch 25/125\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.66732\n",
            "781/781 - 33s - loss: 0.6857 - accuracy: 0.8268 - val_loss: 0.6775 - val_accuracy: 0.8357 - 33s/epoch - 43ms/step\n",
            "Epoch 26/125\n",
            "\n",
            "Epoch 26: val_loss improved from 0.66732 to 0.61600, saving model to model.125epochs.hdf5\n",
            "781/781 - 32s - loss: 0.6806 - accuracy: 0.8317 - val_loss: 0.6160 - val_accuracy: 0.8551 - 32s/epoch - 42ms/step\n",
            "Epoch 27/125\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6750 - accuracy: 0.8326 - val_loss: 0.6787 - val_accuracy: 0.8383 - 33s/epoch - 42ms/step\n",
            "Epoch 28/125\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.61600\n",
            "781/781 - 36s - loss: 0.6721 - accuracy: 0.8341 - val_loss: 0.6720 - val_accuracy: 0.8396 - 36s/epoch - 46ms/step\n",
            "Epoch 29/125\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6782 - accuracy: 0.8315 - val_loss: 0.6498 - val_accuracy: 0.8441 - 33s/epoch - 43ms/step\n",
            "Epoch 30/125\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6696 - accuracy: 0.8365 - val_loss: 0.7276 - val_accuracy: 0.8259 - 33s/epoch - 43ms/step\n",
            "Epoch 31/125\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.61600\n",
            "781/781 - 34s - loss: 0.6705 - accuracy: 0.8349 - val_loss: 0.7429 - val_accuracy: 0.8277 - 34s/epoch - 43ms/step\n",
            "Epoch 32/125\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6635 - accuracy: 0.8385 - val_loss: 0.6610 - val_accuracy: 0.8422 - 33s/epoch - 42ms/step\n",
            "Epoch 33/125\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6641 - accuracy: 0.8379 - val_loss: 0.6809 - val_accuracy: 0.8371 - 35s/epoch - 45ms/step\n",
            "Epoch 34/125\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6577 - accuracy: 0.8415 - val_loss: 0.6727 - val_accuracy: 0.8447 - 33s/epoch - 42ms/step\n",
            "Epoch 35/125\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.61600\n",
            "781/781 - 36s - loss: 0.6604 - accuracy: 0.8411 - val_loss: 0.6902 - val_accuracy: 0.8359 - 36s/epoch - 46ms/step\n",
            "Epoch 36/125\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6559 - accuracy: 0.8412 - val_loss: 0.6871 - val_accuracy: 0.8412 - 33s/epoch - 43ms/step\n",
            "Epoch 37/125\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6568 - accuracy: 0.8417 - val_loss: 0.6968 - val_accuracy: 0.8387 - 33s/epoch - 43ms/step\n",
            "Epoch 38/125\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.61600\n",
            "781/781 - 34s - loss: 0.6511 - accuracy: 0.8426 - val_loss: 0.6522 - val_accuracy: 0.8509 - 34s/epoch - 44ms/step\n",
            "Epoch 39/125\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.61600\n",
            "781/781 - 34s - loss: 0.6509 - accuracy: 0.8442 - val_loss: 0.6691 - val_accuracy: 0.8459 - 34s/epoch - 44ms/step\n",
            "Epoch 40/125\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6494 - accuracy: 0.8440 - val_loss: 0.6441 - val_accuracy: 0.8535 - 35s/epoch - 44ms/step\n",
            "Epoch 41/125\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6465 - accuracy: 0.8463 - val_loss: 0.6184 - val_accuracy: 0.8612 - 35s/epoch - 44ms/step\n",
            "Epoch 42/125\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6500 - accuracy: 0.8456 - val_loss: 0.6615 - val_accuracy: 0.8544 - 33s/epoch - 42ms/step\n",
            "Epoch 43/125\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6429 - accuracy: 0.8477 - val_loss: 0.6445 - val_accuracy: 0.8531 - 35s/epoch - 45ms/step\n",
            "Epoch 44/125\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6453 - accuracy: 0.8451 - val_loss: 0.6368 - val_accuracy: 0.8605 - 33s/epoch - 42ms/step\n",
            "Epoch 45/125\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6447 - accuracy: 0.8488 - val_loss: 0.7089 - val_accuracy: 0.8328 - 33s/epoch - 43ms/step\n",
            "Epoch 46/125\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6426 - accuracy: 0.8493 - val_loss: 0.6934 - val_accuracy: 0.8470 - 35s/epoch - 45ms/step\n",
            "Epoch 47/125\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.61600\n",
            "781/781 - 34s - loss: 0.6367 - accuracy: 0.8510 - val_loss: 0.6434 - val_accuracy: 0.8562 - 34s/epoch - 44ms/step\n",
            "Epoch 48/125\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.61600\n",
            "781/781 - 34s - loss: 0.6393 - accuracy: 0.8496 - val_loss: 0.6371 - val_accuracy: 0.8585 - 34s/epoch - 44ms/step\n",
            "Epoch 49/125\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6365 - accuracy: 0.8516 - val_loss: 0.6949 - val_accuracy: 0.8428 - 35s/epoch - 45ms/step\n",
            "Epoch 50/125\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6429 - accuracy: 0.8500 - val_loss: 0.6614 - val_accuracy: 0.8522 - 33s/epoch - 43ms/step\n",
            "Epoch 51/125\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.61600\n",
            "781/781 - 33s - loss: 0.6363 - accuracy: 0.8510 - val_loss: 0.6638 - val_accuracy: 0.8498 - 33s/epoch - 43ms/step\n",
            "Epoch 52/125\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.61600\n",
            "781/781 - 35s - loss: 0.6410 - accuracy: 0.8493 - val_loss: 0.6655 - val_accuracy: 0.8488 - 35s/epoch - 45ms/step\n",
            "Epoch 53/125\n",
            "\n",
            "Epoch 53: val_loss improved from 0.61600 to 0.61303, saving model to model.125epochs.hdf5\n",
            "781/781 - 34s - loss: 0.6371 - accuracy: 0.8511 - val_loss: 0.6130 - val_accuracy: 0.8670 - 34s/epoch - 43ms/step\n",
            "Epoch 54/125\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.61303\n",
            "781/781 - 35s - loss: 0.6388 - accuracy: 0.8518 - val_loss: 0.7023 - val_accuracy: 0.8441 - 35s/epoch - 44ms/step\n",
            "Epoch 55/125\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.61303\n",
            "781/781 - 34s - loss: 0.6375 - accuracy: 0.8515 - val_loss: 0.6741 - val_accuracy: 0.8498 - 34s/epoch - 44ms/step\n",
            "Epoch 56/125\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.61303\n",
            "781/781 - 35s - loss: 0.6356 - accuracy: 0.8525 - val_loss: 0.6935 - val_accuracy: 0.8493 - 35s/epoch - 44ms/step\n",
            "Epoch 57/125\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.61303\n",
            "781/781 - 36s - loss: 0.6331 - accuracy: 0.8528 - val_loss: 0.6490 - val_accuracy: 0.8583 - 36s/epoch - 46ms/step\n",
            "Epoch 58/125\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6332 - accuracy: 0.8533 - val_loss: 0.6508 - val_accuracy: 0.8578 - 33s/epoch - 43ms/step\n",
            "Epoch 59/125\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6297 - accuracy: 0.8554 - val_loss: 0.6365 - val_accuracy: 0.8630 - 33s/epoch - 42ms/step\n",
            "Epoch 60/125\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.61303\n",
            "781/781 - 34s - loss: 0.6278 - accuracy: 0.8555 - val_loss: 0.6919 - val_accuracy: 0.8435 - 34s/epoch - 44ms/step\n",
            "Epoch 61/125\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.61303\n",
            "781/781 - 34s - loss: 0.6284 - accuracy: 0.8551 - val_loss: 0.6532 - val_accuracy: 0.8526 - 34s/epoch - 44ms/step\n",
            "Epoch 62/125\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.61303\n",
            "781/781 - 35s - loss: 0.6280 - accuracy: 0.8559 - val_loss: 0.6910 - val_accuracy: 0.8429 - 35s/epoch - 45ms/step\n",
            "Epoch 63/125\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.61303\n",
            "781/781 - 35s - loss: 0.6295 - accuracy: 0.8546 - val_loss: 0.6416 - val_accuracy: 0.8568 - 35s/epoch - 45ms/step\n",
            "Epoch 64/125\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.61303\n",
            "781/781 - 35s - loss: 0.6297 - accuracy: 0.8557 - val_loss: 0.6523 - val_accuracy: 0.8565 - 35s/epoch - 44ms/step\n",
            "Epoch 65/125\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6204 - accuracy: 0.8582 - val_loss: 0.7231 - val_accuracy: 0.8388 - 33s/epoch - 43ms/step\n",
            "Epoch 66/125\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6269 - accuracy: 0.8565 - val_loss: 0.7227 - val_accuracy: 0.8294 - 33s/epoch - 42ms/step\n",
            "Epoch 67/125\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6228 - accuracy: 0.8573 - val_loss: 0.6821 - val_accuracy: 0.8480 - 33s/epoch - 42ms/step\n",
            "Epoch 68/125\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6249 - accuracy: 0.8571 - val_loss: 0.6914 - val_accuracy: 0.8408 - 33s/epoch - 43ms/step\n",
            "Epoch 69/125\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.61303\n",
            "781/781 - 34s - loss: 0.6272 - accuracy: 0.8558 - val_loss: 0.6882 - val_accuracy: 0.8472 - 34s/epoch - 44ms/step\n",
            "Epoch 70/125\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.61303\n",
            "781/781 - 33s - loss: 0.6207 - accuracy: 0.8571 - val_loss: 0.7579 - val_accuracy: 0.8360 - 33s/epoch - 42ms/step\n",
            "Epoch 71/125\n",
            "\n",
            "Epoch 71: val_loss improved from 0.61303 to 0.58458, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 0.6203 - accuracy: 0.8592 - val_loss: 0.5846 - val_accuracy: 0.8765 - 33s/epoch - 42ms/step\n",
            "Epoch 72/125\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6209 - accuracy: 0.8583 - val_loss: 0.6075 - val_accuracy: 0.8655 - 33s/epoch - 42ms/step\n",
            "Epoch 73/125\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.58458\n",
            "781/781 - 35s - loss: 0.6244 - accuracy: 0.8572 - val_loss: 0.6376 - val_accuracy: 0.8618 - 35s/epoch - 44ms/step\n",
            "Epoch 74/125\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6191 - accuracy: 0.8593 - val_loss: 0.6659 - val_accuracy: 0.8542 - 33s/epoch - 42ms/step\n",
            "Epoch 75/125\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6194 - accuracy: 0.8579 - val_loss: 0.6611 - val_accuracy: 0.8523 - 33s/epoch - 43ms/step\n",
            "Epoch 76/125\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6155 - accuracy: 0.8610 - val_loss: 0.6506 - val_accuracy: 0.8556 - 34s/epoch - 44ms/step\n",
            "Epoch 77/125\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6155 - accuracy: 0.8602 - val_loss: 0.6139 - val_accuracy: 0.8711 - 34s/epoch - 43ms/step\n",
            "Epoch 78/125\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.58458\n",
            "781/781 - 35s - loss: 0.6131 - accuracy: 0.8603 - val_loss: 0.6231 - val_accuracy: 0.8623 - 35s/epoch - 44ms/step\n",
            "Epoch 79/125\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6190 - accuracy: 0.8591 - val_loss: 0.6801 - val_accuracy: 0.8473 - 33s/epoch - 43ms/step\n",
            "Epoch 80/125\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6155 - accuracy: 0.8590 - val_loss: 0.7008 - val_accuracy: 0.8466 - 33s/epoch - 42ms/step\n",
            "Epoch 81/125\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6088 - accuracy: 0.8628 - val_loss: 0.6675 - val_accuracy: 0.8548 - 33s/epoch - 43ms/step\n",
            "Epoch 82/125\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6098 - accuracy: 0.8614 - val_loss: 0.6422 - val_accuracy: 0.8613 - 34s/epoch - 44ms/step\n",
            "Epoch 83/125\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6107 - accuracy: 0.8616 - val_loss: 0.6449 - val_accuracy: 0.8574 - 33s/epoch - 43ms/step\n",
            "Epoch 84/125\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6119 - accuracy: 0.8620 - val_loss: 0.6360 - val_accuracy: 0.8633 - 33s/epoch - 42ms/step\n",
            "Epoch 85/125\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.58458\n",
            "781/781 - 35s - loss: 0.6162 - accuracy: 0.8598 - val_loss: 0.6163 - val_accuracy: 0.8674 - 35s/epoch - 45ms/step\n",
            "Epoch 86/125\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6134 - accuracy: 0.8600 - val_loss: 0.6705 - val_accuracy: 0.8518 - 33s/epoch - 42ms/step\n",
            "Epoch 87/125\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6120 - accuracy: 0.8606 - val_loss: 0.6004 - val_accuracy: 0.8710 - 33s/epoch - 43ms/step\n",
            "Epoch 88/125\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6123 - accuracy: 0.8606 - val_loss: 0.6751 - val_accuracy: 0.8577 - 33s/epoch - 43ms/step\n",
            "Epoch 89/125\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.58458\n",
            "781/781 - 35s - loss: 0.6084 - accuracy: 0.8619 - val_loss: 0.6722 - val_accuracy: 0.8549 - 35s/epoch - 45ms/step\n",
            "Epoch 90/125\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6073 - accuracy: 0.8620 - val_loss: 0.6613 - val_accuracy: 0.8592 - 33s/epoch - 43ms/step\n",
            "Epoch 91/125\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.58458\n",
            "781/781 - 37s - loss: 0.6091 - accuracy: 0.8640 - val_loss: 0.6300 - val_accuracy: 0.8619 - 37s/epoch - 47ms/step\n",
            "Epoch 92/125\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6115 - accuracy: 0.8606 - val_loss: 0.6410 - val_accuracy: 0.8621 - 34s/epoch - 43ms/step\n",
            "Epoch 93/125\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.58458\n",
            "781/781 - 35s - loss: 0.6097 - accuracy: 0.8613 - val_loss: 0.6180 - val_accuracy: 0.8697 - 35s/epoch - 45ms/step\n",
            "Epoch 94/125\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6074 - accuracy: 0.8621 - val_loss: 0.6166 - val_accuracy: 0.8644 - 34s/epoch - 44ms/step\n",
            "Epoch 95/125\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6069 - accuracy: 0.8619 - val_loss: 0.6520 - val_accuracy: 0.8551 - 33s/epoch - 42ms/step\n",
            "Epoch 96/125\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6090 - accuracy: 0.8625 - val_loss: 0.6952 - val_accuracy: 0.8473 - 33s/epoch - 42ms/step\n",
            "Epoch 97/125\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.58458\n",
            "781/781 - 34s - loss: 0.6085 - accuracy: 0.8611 - val_loss: 0.6920 - val_accuracy: 0.8458 - 34s/epoch - 44ms/step\n",
            "Epoch 98/125\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.58458\n",
            "781/781 - 33s - loss: 0.6113 - accuracy: 0.8608 - val_loss: 0.7103 - val_accuracy: 0.8389 - 33s/epoch - 42ms/step\n",
            "Epoch 99/125\n",
            "\n",
            "Epoch 99: val_loss improved from 0.58458 to 0.57943, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 0.6063 - accuracy: 0.8627 - val_loss: 0.5794 - val_accuracy: 0.8764 - 33s/epoch - 43ms/step\n",
            "Epoch 100/125\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.57943\n",
            "781/781 - 35s - loss: 0.6091 - accuracy: 0.8625 - val_loss: 0.6424 - val_accuracy: 0.8595 - 35s/epoch - 44ms/step\n",
            "Epoch 101/125\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.57943\n",
            "781/781 - 35s - loss: 0.6079 - accuracy: 0.8621 - val_loss: 0.6301 - val_accuracy: 0.8636 - 35s/epoch - 45ms/step\n",
            "Epoch 102/125\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6048 - accuracy: 0.8635 - val_loss: 0.6577 - val_accuracy: 0.8617 - 33s/epoch - 42ms/step\n",
            "Epoch 103/125\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6084 - accuracy: 0.8610 - val_loss: 0.6332 - val_accuracy: 0.8657 - 33s/epoch - 42ms/step\n",
            "Epoch 104/125\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.57943\n",
            "781/781 - 35s - loss: 0.6087 - accuracy: 0.8616 - val_loss: 0.6139 - val_accuracy: 0.8691 - 35s/epoch - 45ms/step\n",
            "Epoch 105/125\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.57943\n",
            "781/781 - 32s - loss: 0.6066 - accuracy: 0.8611 - val_loss: 0.6497 - val_accuracy: 0.8616 - 32s/epoch - 42ms/step\n",
            "Epoch 106/125\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6032 - accuracy: 0.8639 - val_loss: 0.6888 - val_accuracy: 0.8521 - 33s/epoch - 42ms/step\n",
            "Epoch 107/125\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6077 - accuracy: 0.8621 - val_loss: 0.6250 - val_accuracy: 0.8662 - 33s/epoch - 42ms/step\n",
            "Epoch 108/125\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.57943\n",
            "781/781 - 35s - loss: 0.6053 - accuracy: 0.8636 - val_loss: 0.7053 - val_accuracy: 0.8461 - 35s/epoch - 44ms/step\n",
            "Epoch 109/125\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6066 - accuracy: 0.8640 - val_loss: 0.6229 - val_accuracy: 0.8664 - 33s/epoch - 42ms/step\n",
            "Epoch 110/125\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6017 - accuracy: 0.8648 - val_loss: 0.6962 - val_accuracy: 0.8471 - 33s/epoch - 42ms/step\n",
            "Epoch 111/125\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.57943\n",
            "781/781 - 34s - loss: 0.6044 - accuracy: 0.8649 - val_loss: 0.6115 - val_accuracy: 0.8713 - 34s/epoch - 44ms/step\n",
            "Epoch 112/125\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.57943\n",
            "781/781 - 34s - loss: 0.5994 - accuracy: 0.8664 - val_loss: 0.5975 - val_accuracy: 0.8744 - 34s/epoch - 44ms/step\n",
            "Epoch 113/125\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.57943\n",
            "781/781 - 33s - loss: 0.6032 - accuracy: 0.8659 - val_loss: 0.6229 - val_accuracy: 0.8682 - 33s/epoch - 42ms/step\n",
            "Epoch 114/125\n",
            "\n",
            "Epoch 114: val_loss improved from 0.57943 to 0.57324, saving model to model.125epochs.hdf5\n",
            "781/781 - 33s - loss: 0.6021 - accuracy: 0.8644 - val_loss: 0.5732 - val_accuracy: 0.8792 - 33s/epoch - 42ms/step\n",
            "Epoch 115/125\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.57324\n",
            "781/781 - 34s - loss: 0.6024 - accuracy: 0.8656 - val_loss: 0.6742 - val_accuracy: 0.8530 - 34s/epoch - 44ms/step\n",
            "Epoch 116/125\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.57324\n",
            "781/781 - 33s - loss: 0.6052 - accuracy: 0.8631 - val_loss: 0.7058 - val_accuracy: 0.8483 - 33s/epoch - 43ms/step\n",
            "Epoch 117/125\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.57324\n",
            "781/781 - 35s - loss: 0.6044 - accuracy: 0.8640 - val_loss: 0.6867 - val_accuracy: 0.8570 - 35s/epoch - 45ms/step\n",
            "Epoch 118/125\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.57324\n",
            "781/781 - 33s - loss: 0.6079 - accuracy: 0.8616 - val_loss: 0.6393 - val_accuracy: 0.8621 - 33s/epoch - 42ms/step\n",
            "Epoch 119/125\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.57324\n",
            "781/781 - 33s - loss: 0.6007 - accuracy: 0.8650 - val_loss: 0.6117 - val_accuracy: 0.8649 - 33s/epoch - 42ms/step\n",
            "Epoch 120/125\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.57324\n",
            "781/781 - 35s - loss: 0.6020 - accuracy: 0.8651 - val_loss: 0.6932 - val_accuracy: 0.8507 - 35s/epoch - 45ms/step\n",
            "Epoch 121/125\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.57324\n",
            "781/781 - 33s - loss: 0.6043 - accuracy: 0.8646 - val_loss: 0.6135 - val_accuracy: 0.8663 - 33s/epoch - 42ms/step\n",
            "Epoch 122/125\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.57324\n",
            "781/781 - 33s - loss: 0.5996 - accuracy: 0.8666 - val_loss: 0.6976 - val_accuracy: 0.8475 - 33s/epoch - 42ms/step\n",
            "Epoch 123/125\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.57324\n",
            "781/781 - 34s - loss: 0.6023 - accuracy: 0.8656 - val_loss: 0.6528 - val_accuracy: 0.8627 - 34s/epoch - 43ms/step\n",
            "Epoch 124/125\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.57324\n",
            "781/781 - 35s - loss: 0.5980 - accuracy: 0.8663 - val_loss: 0.6072 - val_accuracy: 0.8730 - 35s/epoch - 44ms/step\n",
            "Epoch 125/125\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.57324\n",
            "781/781 - 34s - loss: 0.6008 - accuracy: 0.8659 - val_loss: 0.6105 - val_accuracy: 0.8683 - 34s/epoch - 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqTt2nd53uoU",
        "outputId": "1b68e0a1-d8dd-4a59-ef63-80be6b76c9b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 11ms/step - loss: 0.6105 - accuracy: 0.8683\n",
            "\n",
            "Test result: 86.830 loss: 0.611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curves of model accuracy\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "YO7XaCZIOq7n",
        "outputId": "150dc22d-985f-41a6-ff82-f4e006c8f4ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mBPa1LLOzHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}